
Wikilon will host a set of abstract virtual machines, which I'm calling AVMs.

Each AVM has [state](StateModels.md), initialized on construction, and a step function bound to a [dictionary](BranchingDictionary.md) for live programming. AVMs and their state are *purely functional*. While AVMs lack internal concurrency, they should support reasonable levels for internal parallelism. Wikilon will keep logarithmic histories for full AVMs to support debugging, recovery. Pure functions might also be leveraged for easy forking. Hierarchical AVMs should be entirely feasible, i.e. modeling a larger AVM in terms of simulating smaller ones with a user-defined networking behavior. However, I also want AVMs for scalability, distribution, and maybe (hopefully, eventually!) the ability to compile an AVM into a tiny process or unikernel.

Those last few conditions are important. Our network model must:

* support a purely functional implementation
* address concerns of non-determinism and consistency
* address concerns of disruption, latency
* address scalability concerns
 * replication for read-only queries?
 * potential for implicit sharding?
* address security concerns
 * malformed or malign messages
 * denial of service attack

A purely functional simulation of a network will be deterministic. But, from the perspective of an AVM, the network must be considered non-deterministic and unreliable. How much non-determinism is acceptable? A careful design of the network model has potential to mitigate consistency issues.

One idea I developed earlier is that of *transactional batches:*

* messages are organized in transactional batches 
 * messages in a batch are processed atomically
 * messages generated by a batch form new batches
 * messages within a batch processed in order 
* batches between two AVMs are also ordered
 * multiple batches may have an ordering
 * may need a logical connections model
 * maybe name connections instead of AVMs?

This supports a useful 'snapshot' consistency between AVMs, basically what I had for RDP vats in Sirea.

While it doesn't provide global consistency, but it does support 'snapshot' consistency between AVMs. This potentially avoids a great many problems.

The RDP Vat model in Sirea used a similar basis. 

It provides a rather simple basis for *local* transactions.


Another, much older idea is *time warp*. In this idea, our messages are given logical timestamps, and we might undo and replay communications if some messages arrive out of order. Howe


I like this idea of making 'message batches' the first-class message type.
 


 messages emitted within a transaction will be received in 







## Transactions and Batches

State is updated using ACId transactions. Durability won't be the default (since this is VCache), but may be requested (in which case all outgoing messages would wait for sync). Naturally, outgoing messages or effects from an AVM must be delayed until the transaction commits. Consequently, we will have 'batches' of generated messages moving towards multiple targets. 

I will preserve this batching in the receiver. Thus, the primary unit of communication between abstract machines becomes *batches of messages*. Messages between AVMs will also preserve serialization order - i.e. an earlier batch will always run before a later batch. Messages are also ordered within each batch. This provides a useful 'snapshot consistency' when viewing other AVMs.

Each AVM is, more or less, a 'vat' in the E parlance. But plus many nice atomicity and consistency properties. These properties will be preserved if we compile AVMs to a separate process or unikernel.

*Note:* I may need to model logical connections to handle disruption and latency effectively. Further, it might be useful to separate batches from stability such that we have a rollback window between AVMs (i.e. Time Warp).